{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimention reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = 'Cultivars'\n",
    "\n",
    "feature_cols = [\n",
    "        'Alcohol',\n",
    "        'Malic_acid',\n",
    "        'Ash',\n",
    "        'Alcalinity_of_ash',\n",
    "        'Magnesium',\n",
    "        'Total_phenols',\n",
    "        'Flavanoids',\n",
    "        'Nonflavanoid_phenols',\n",
    "        'Proanthocyanins',\n",
    "        'Color_intensity',\n",
    "        'Hue',\n",
    "        'OD280/OD315_of_diluted_wines',\n",
    "        'Proline'\n",
    "    ]\n",
    "\n",
    "cols = feature_cols.copy()\n",
    "cols.insert(0, class_name)\n",
    "\n",
    "df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data', \n",
    "                 header=None, names=cols)\n",
    "\n",
    "features = df.drop(class_name, axis=1)\n",
    "target = df[class_name]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Fitting the PCA algorithm with our Data\n",
    "pca = PCA().fit(features)\n",
    "\n",
    "#Plotting the Cumulative Summation of the Explained Variance\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') #for each component\n",
    "plt.title('Wine Dataset Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_features_and_class(features_, class_):\n",
    "    df_ = pd.DataFrame({'x': features_[:, 0], 'y': features_[:, 1]})\n",
    "    result = pd.concat([df_, class_], axis=1, sort=False)\n",
    "    return result\n",
    "\n",
    "def plot_reduced_dataset(df_):\n",
    "    groups = df_.groupby(class_name)\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(15, 7)\n",
    "    ax.margins(0.05)\n",
    "    for name, group in groups:\n",
    "        ax.plot(group.x, group.y, marker='o', linestyle='', ms='7', label=name)\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "reduced_features = pca.fit_transform(features)\n",
    "res_pca = zip_features_and_class(reduced_features, target)\n",
    "res_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reduced_dataset(res_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "reduced_features = tsne.fit_transform(features)\n",
    "res_tsne = zip_features_and_class(reduced_features, target)\n",
    "res_tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_reduced_dataset(res_tsne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "train_all = fetch_20newsgroups(subset='train')\n",
    "train_all.target_names\n",
    "\n",
    "categories = ['sci.crypt', 'sci.space', 'comp.windows.x']\n",
    "data_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join(data_train.data[0].split(\"\\n\")[:3]))\n",
    "print()\n",
    "print(data_train.target_names[data_train.target[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(lowercase=True, stop_words='english')\n",
    "X_train_counts = count_vect.fit_transform(data_train.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "def report(actual, predicted):\n",
    "    print('Accuracy: {0}\\n'.format(accuracy_score(actual, predicted)))\n",
    "    print('Confusion matrix:\\n\\n {0}\\n'.format(confusion_matrix(actual, predicted)))\n",
    "    print('Classification report:\\n\\n {0}'.format(classification_report(actual, predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train_tfidf, data_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "docs_test = twenty_test.data\n",
    "docs_test = count_vect.transform(docs_test)\n",
    "docs_test = tfidf_transformer.transform(docs_test)\n",
    "print(docs_test.shape)\n",
    "print()\n",
    "\n",
    "predicted = rfc.predict(docs_test)\n",
    "report(twenty_test.target, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multidict as multidict\n",
    "\n",
    "import os\n",
    "import re\n",
    "from PIL import Image\n",
    "from os import path\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "def getFrequencyDictForText(texts):\n",
    "    fullTermsDict = multidict.MultiDict()\n",
    "    tmpDict = {}\n",
    "\n",
    "    # making dict for counting frequencies\n",
    "    for t in texts:\n",
    "        for text in t.split(\" \"):\n",
    "            if re.match(\"a|the|an|the|to|in|for|of|or|by|with|is|on|that|be\", text):\n",
    "                continue\n",
    "            val = tmpDict.get(text, 0)\n",
    "            tmpDict[text.lower()] = val + 1\n",
    "    for key in tmpDict:\n",
    "        fullTermsDict.add(key, tmpDict[key])\n",
    "    return fullTermsDict\n",
    "        \n",
    "\n",
    "def makeImage(text):\n",
    "    wc = WordCloud(background_color=\"white\", max_words=1000)\n",
    "    # generate word cloud\n",
    "    wc.generate_from_frequencies(text)\n",
    "\n",
    "    # show\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makeImage(getFrequencyDictForText(data_train.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD()\n",
    "X_train_svd = svd.fit_transform(X_train_tfidf)\n",
    "X_train_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_named = [data_train.target_names[target] for target in data_train.target]\n",
    "\n",
    "text_df = zip_features_and_class(X_train_svd, pd.DataFrame({'topic':target_named}))\n",
    "\n",
    "groups = text_df.groupby('topic')\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(15, 7)\n",
    "ax.margins(0.05)\n",
    "for name, group in groups:\n",
    "    ax.plot(group.x, group.y, marker='o', linestyle='', ms='7', label=name)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "\n",
    "kmeans.fit(X_train_svd)\n",
    "y_kmeans = kmeans.predict(X_train_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.scatter(X_train_svd[:, 0], X_train_svd[:, 1], c=y_kmeans, s=50, cmap='viridis')\n",
    "\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df_.groupby(class_name)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(15, 7)\n",
    "ax.margins(0.05)\n",
    "for name, group in groups:\n",
    "    ax.plot(group.x, group.y, marker='o', linestyle='', ms='7', label=name)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
